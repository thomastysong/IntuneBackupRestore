# Intune Configuration Backup as Code – Design Document

## Metadata

**Project Title:** Intune Configuration Backup Automation (GitHub Actions)  
**Project Summary:** Design a system to automatically export and version all Microsoft Intune configurations to a Git repository, with a scheduled weekly backup and change tracking. The system will fetch Intune policies and settings via Microsoft Graph API, store them as code (JSON/YAML), and generate a structured JSON change log for monitoring.  
**uOwn Asset / Team:** Client Platform Engineering (Device Management)  
**Date Started:** August 20, 2025

## Justification

Intune configurations are constantly evolving – Microsoft updates Intune nearly every week[\[1\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=If%20there%E2%80%99s%20anything%20that%E2%80%99s%20certain,receives%20updates%20almost%20every%20week), and administrators frequently adjust policies. Currently, Intune provides no native versioning or comprehensive change tracking for configurations[\[2\]](https://rozemuller.com/manage-intune-scripts-with-github-actions/#:~:text=Currently%2C%20Intune%20does%20not%20provide,committed%20to%20a%20GitHub%20repository). This poses challenges in troubleshooting and compliance, as changes can be made without an easy way to compare current settings to previous states. Manually documenting “as-built” configurations quickly becomes outdated[\[1\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=If%20there%E2%80%99s%20anything%20that%E2%80%99s%20certain,receives%20updates%20almost%20every%20week). What the IT operations team needs is an automated way to **track every change** in Intune over time[\[3\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=What%20is%20more%20valuable%20to,blame%20game%20is%20not%20healthy).

By **treating Intune configurations as code**, we enable robust version control. Every policy, profile, app configuration, or role can be captured in JSON form and committed to a Git repository. This brings multiple benefits: (1) a historical record of all changes (with diff capabilities) for audits and troubleshooting[\[3\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=What%20is%20more%20valuable%20to,blame%20game%20is%20not%20healthy), (2) the ability to **roll back or recreate** configurations if needed by referencing prior versions, and (3) improved collaboration and review of changes via code workflows. In short, this project will transform Intune into an Infrastructure-as-Code paradigm, providing transparency and safety for device management changes.

Moreover, automating backups addresses business continuity and compliance requirements. If an erroneous change is introduced, having last week’s known-good configuration in Git makes it easier to identify the difference and remediate. We can also detect unauthorized or unintended changes by reviewing the weekly diffs. Overall, this solution reduces risk and increases confidence in the stability of our endpoint management, aligning with best practices of modern DevOps/DevSecOps for infrastructure management.

## Background

Our organization (and many others) currently manages Intune settings through the Azure portal or ad-hoc scripts, without a unified version control. In the past, engineers have relied on manual exports or third-party scripts to back up Intune. For example, a PowerShell community module **IntuneBackupAndRestore** has existed to export Intune configs to JSON and even compare or restore them[\[4\]](https://www.thelazyadministrator.com/2019/11/26/backup-and-restore-your-intune-configuration-using-powershell/#:~:text=I%20found%20this%20fantastic%20PowerShell,compare%20different%20Intune%20backup%20sets). Another tool, **IntuneCD** (Config Deployment), written in Python, can export Intune configurations and even generate documentation[\[5\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=The%20IntuneBackupAndRestore%20PowerShell%20module%20has,single%20tenant%20or%20across%20tenants). These efforts validate the approach of backing up Intune to files. Our design builds on these ideas but provides a cohesive, organization-ready system integrated with CI/CD.

Notably, prior approaches required running scripts on-demand or via Azure Automation. We aim to modernize this by using **GitHub Actions on a schedule**, eliminating the need for separate infrastructure. We’ll incorporate lessons from those tools: for instance, IntuneCD outputs configurations in JSON/YAML which are easily tracked in Git[\[6\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=Hosting%20the%20exported%20configurations%20in,Git%20version%20history%20is%20easy), and Andrew Taylor’s Intune backup script demonstrated parameterizing credentials so the solution can work across tenants/customers[\[7\]](https://andrewstaylor.com/2022/12/07/intune-backing-up-and-restoring-your-environment-new-and-improved/#:~:text=,new%20Graph%20SDK).

Currently, any change in Intune is tracked only in Intune’s audit logs and perhaps manually recorded in change tickets. There is no central repository for “ground truth” of Intune settings. This gap has led to situations where troubleshooting a device issue required manually cross-referencing what policies were in place at a given time. By introducing automated backups and change logs, we provide that central source of truth. This project does not replace Intune or alter how admins make changes (at least initially); it runs in parallel to **capture state**. Over time, it could enable a true GitOps flow (making changes via Git commits), but initially the focus is on backup and monitoring of changes.

In summary, the background research and existing tooling show it’s feasible to export the entire Intune configuration (profiles, policies, apps, assignments, etc.) via Graph API. Our task is to integrate that into a maintainable pipeline, tailor it for our environment, and ensure it’s secure and extensible for future needs.

## Architecture

![][image1]  
*High-Level Architecture – The backup workflow and data flow for Intune Configuration as Code.*

At a high level, our solution will run as a **GitHub Actions workflow** on a schedule (e.g. every week). The GitHub Actions workflow triggers a set of **Intune Export Modules** implemented in PowerShell and/or Python. These modules authenticate to Microsoft Graph for Intune using an Azure AD app registration and query all relevant Intune configuration objects. The **Microsoft Graph API** (Intune service) is the source of truth for configuration data, and our modules will systematically fetch **all components** (configuration profiles, compliance policies, application assignments and configurations, device scripts, device/user group assignments, Intune RBAC roles, etc.). We use whichever language (PowerShell or Python) is most stable for each component’s API – for example, leveraging the Microsoft Graph PowerShell SDK for some endpoints and a Python Graph SDK or direct REST calls for others. Each module is responsible for one category of Intune objects, outputting the data in a structured JSON (or YAML) file representing that object’s configuration.

Within the GitHub Actions workflow, after exporting data, we perform a **JSON diff generation step**. This step compares the newly exported configuration files with the previous version from last week (stored in the Git repo). The comparison logic will identify any additions, removals, or modifications in the Intune configs. A **change log JSON file** is then produced, summarizing these differences with metadata (timestamp, object type, object identifier, and details of changes). Finally, the workflow commits the updated configuration files and the new JSON change log to the Git repository. The repository thus always contains the latest snapshot of Intune config as code, and a history of change logs.

The above diagram illustrates this flow: **GitHub Actions** (with a scheduled trigger) initiates the backup process. The action runs the **Intune export scripts** (PowerShell/Python), which **fetch data via Graph API** and output the config files. The workflow then calls a **diff generator** module that reads the current export and the last export (from the repo) to compute differences, writing out a JSON log. All changes are then **committed to the Git repo** (which is configured as private and secure). Separately, our monitoring system (e.g. Grafana) is set up to consume the JSON change log for visualization and alerting on changes. Grafana could pull the JSON directly from the repo or via an API, and display recent changes or trigger alerts if certain critical policies were modified. This end-to-end design marries configuration management with monitoring: every week, we not only back up the data but also flag what changed in a format that’s easy to review.

Key design points include modularity and reusability. Each export module has a well-defined boundary (e.g., a script to export “Compliance Policies” knows how to query all deviceCompliancePolicy objects and their settings, then save to Intune/CompliancePolicies/\<Name\>.json). This modular approach means we can add new Intune components easily by writing a new module and plugging it into the workflow. The system is configured via environment variables or a .env file (for local testing) to provide tenant-specific info – *no hardcoded tenant IDs or secrets*. In GitHub Actions, these values (Tenant ID, Client ID, Client Secret, etc.) will be stored as secrets and injected as env vars at runtime[\[8\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=Create%20the%20following%20secrets%20on,the%20repository). This makes the solution **portable** across different organizations or tenants by simply changing configuration, not code.

Finally, the architecture assumes using a GitHub-hosted runner (or potentially a self-hosted runner) that has PowerShell and Python environments available. GitHub’s cloud runners on Windows can easily run PowerShell scripts and also install Python packages (like IntuneCD or MS Graph SDK) as needed[\[9\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=This%20workflow%20performs%20the%20following,tasks). The workflow will perform steps such as installing required modules (e.g., Install-Module Microsoft.Graph or pip install IntuneCD) before running exports[\[10\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=,built%20in%20markdown%20format). All secrets are provided via secure GitHub Secrets store, and access to the repo for committing is handled by GitHub’s token (or a PAT if needed for tagging)[\[11\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=%2A%20%60CLIENT_SECRET%60%20,the%20user%20for%20Git%20commits).

This architecture leverages **proven patterns** from prior art: for example, the IntuneCD workflow design (backup \-\> document \-\> commit)[\[9\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=This%20workflow%20performs%20the%20following,tasks) and the recommendation to use a **private git repo for sensitive configs**[\[12\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=It%E2%80%99s%20vitally%20important%20that%20the,how%20you%20secure%20your%20devices). It extends those with a bespoke diff generation and integration with Grafana. The result is an automated pipeline that runs with no human intervention, reliably backing up our Intune configuration weekly and surfacing any changes for the team’s awareness.

## Implementation Plan

**1\. Prepare Azure AD App Registration for Graph Access:** We will create an app registration in Azure AD with **application (client) credentials** for Graph API. This app will be granted least-privilege Graph API permissions needed to read Intune config. At a minimum, we need DeviceManagementConfiguration.Read.All for most Intune data[\[13\]](https://github.com/almenscorner/IntuneCD/discussions/153#:~:text=It%20should%20be%20enough%20with,All), and DeviceManagementRBAC.Read.All to include Intune role assignments[\[14\]](https://github.com/almenscorner/IntuneCD/discussions/153#:~:text=To%20export%20the%20roles%20the,All%20correct). We will generate a client secret (or certificate) for the app. The Tenant ID, Client ID, and Client Secret will be noted for the next steps. This allows **non-interactive authentication** in CI/CD. (No user accounts or MFA prompts — the workflow will use client credentials flow to connect.)

**2\. Set up GitHub Repository and Secrets:** We will create a new private GitHub repository (or use an existing one in our org) to host the configuration files. The repository will contain an initial skeleton structure of directories for each Intune component (e.g. CompliancePolicies/, ConfigProfiles/, Apps/, Assignments/, Roles/, etc.), which the export scripts will populate. In the repo’s settings, define secrets for AZURE\_TENANT\_ID, AZURE\_CLIENT\_ID, and AZURE\_CLIENT\_SECRET (and any other relevant env vars like GRAPH\_SCOPES if needed). The GitHub Actions workflow will load these secrets as environment variables. (We follow Microsoft’s guidance for environment-based auth: the Microsoft Graph PowerShell SDK can use AZURE\_CLIENT\_ID etc. to authenticate[\[15\]](https://techcommunity.microsoft.com/blog/intunecustomersuccess/configuration-as-code-for-microsoft-intune/3701792#:~:text=,secret%20of%20the%20client%20app).) Also store any other secrets: e.g., if using a Personal Access Token for pushing commits or tags (though we can usually use the default GitHub token for committing to the same repo).

**3\. Develop Export Modules for Each Intune Object Type:** For each category of Intune configuration, we will implement a script or module to retrieve it from Graph and output to a file. We will start with the core components: \- **Configuration Profiles** (deviceConfiguration objects) – Export each profile’s JSON (including its OMA-URI or template settings). \- **Compliance Policies** (deviceCompliancePolicy objects) – Export each policy’s JSON definition. \- **Applications and App Protection/Configuration** – Export managed app configurations and assignments. \- **Device Scripts / Proactive Remediations** – Export device management scripts. For scripts, we will store the metadata as JSON and the script content as plain text .ps1 files for readability (converting from base64)[\[16\]](https://www.thelazyadministrator.com/2019/11/26/backup-and-restore-your-intune-configuration-using-powershell/#:~:text=If%20I%20navigate%20to%20that,will%20be%20PS1%20source%20files). \- **Device & User Assignments** – For each policy/profile, also capture the assigned groups. This might be embedded in the JSON or retrieved via separate Graph calls (e.g., /assignments endpoints). We ensure that the assignment (list of group IDs or names) is saved, so that changes in scope are tracked. \- **Role Definitions and Role Assignments** – Export custom Intune roles and their assignments (who is in each role). Built-in roles might be skipped or handled separately (since they can’t be modified). \- **Additional**: Scope tags, enrollment restrictions, device categories, or any other Intune setting not covered above. We plan modules for these as needed, and our framework allows adding them easily.

Each module can be implemented in whichever language is more appropriate: \- For example, **IntuneCD (Python)** already handles many of these categories and could be invoked for a quick implementation[\[5\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=The%20IntuneBackupAndRestore%20PowerShell%20module%20has,single%20tenant%20or%20across%20tenants). We might wrap IntuneCD calls for things it supports (backup to JSON/YAML). \- For other areas or fine-grained control, we use **PowerShell** with the Graph SDK. E.g., a PowerShell script might use Get-MgDeviceManagementDeviceConfiguration for config profiles, Get-MgDeviceManagementDeviceCompliancePolicy for compliance, etc., then use ConvertTo-Json to output. We can also use direct Graph REST calls via Invoke-WebRequest/Invoke-RestMethod or the Python requests library for endpoints not covered by SDKs or to use beta endpoints if required. \- We ensure each module writes output to a defined path in the repo working directory, following a consistent naming convention (perhaps \<ComponentType\>/\<Name\>-\<id\>.json for uniqueness). The export format will be prettified JSON for diff-friendliness. Any binary data (like certificates or script content) will be handled (e.g., script contents decoded as mentioned, certificates perhaps skipped or stored securely if needed).

We will also include in each JSON a few metadata fields like the Intune object’s unique ID and perhaps last modified time (if provided by Graph). This can help identify objects even if names change and could be used in diffs.

**4\. Implement the JSON Diff Generator:** Develop a Python script (or could be PowerShell) that runs after the export modules. This script will load the **previous** commit’s files and the **current** export files, and compute changes. Since the repository is version-controlled, the previous state is essentially the HEAD of the main branch (before this workflow’s changes). In the GitHub Actions context, we will have the repository checked out at the start; we might store a copy of it before overwriting, or use git diff as a helper. Our approach: \- For each file representing an Intune object, determine if it is new (present in current export but not in previous commit), removed (in previous commit but not in current), or modified (present in both but contents differ). \- For modified files, do a JSON structural comparison to identify which fields changed. We can use a Python library (like DeepDiff) or manual comparison. The output should list the specific keys or settings that changed and their old vs new values. For example, if a compliance policy had “minPasswordLength” changed from 6 to 8, the diff entry would capture that. \- Aggregate the changes into a JSON object with sections for "added", "removed", "modified". Each added/removed item can include object type and name/ID. Each modified item will include the object and a list or map of changed fields (with old/new values). \- Include a timestamp of when the diff was generated, and possibly the author (could use a service account name). Also include an overall summary (e.g., X objects added/removed/modified).

The result is saved to a file, e.g., change\_logs/\<timestamp\>\_changeLog.json or simply changeLog.json (overwriting each time). We prefer a timestamped filename for historical record. This JSON will be structured such that Grafana (or another tool) can parse it easily – likely an array of changes with consistent fields. **Example JSON structure:**

{  
  "timestamp": "2025-08-20T07:43:30Z",  
  "added": \[  
    {  
      "objectType": "DeviceCompliancePolicy",  
      "displayName": "EncryptionRequired",  
      "objectId": "abcd-1234-efgh",  
      "details": { ... optional summary of settings ... }  
    }  
  \],  
  "removed": \[  
    {  
      "objectType": "AppConfiguration",  
      "displayName": "LegacyAppConfig",  
      "objectId": "zyxw-9876",  
      "details": null  
    }  
  \],  
  "modified": \[  
    {  
      "objectType": "DeviceConfigurationProfile",  
      "displayName": "Windows 10 Security Baseline",  
      "objectId": "1122-3344",  
      "changes": {  
        "passwordRequired": { "old": false, "new": true },  
        "minPasswordLength": { "old": 4, "new": 6 }  
      }  
    }  
  \]  
}

Each modified entry lists the specific settings changed. This level of detail provides immediate insight into what changed each week, without needing to manually diff long JSON files. (It’s akin to how one might manually compare two JSON backups and spot that a PIN length changed[\[17\]](https://www.thelazyadministrator.com/2019/11/26/backup-and-restore-your-intune-configuration-using-powershell/#:~:text=To%20now%20compare%20both%20configuration,My%20full%20scriptblock%20would%20be) – here the tool will highlight that for us.)

**5\. Configure the GitHub Actions Workflow:** We will create a YAML workflow file (e.g., .github/workflows/intune-backup.yml) that ties everything together. Key steps: \- **Trigger:** Use the schedule: trigger to run at a given CRON time weekly (e.g., every Monday at 00:00). Also allow manual trigger (workflow\_dispatch) so we can run on-demand if needed. \- **Job Setup:** Use a Windows runner (for easy PowerShell integration) or possibly an Ubuntu runner if we decide to run everything in Python. We can actually have a matrix or separate jobs if we want to split PowerShell and Python tasks. \- **Checkout code:** Use actions/checkout to pull the repo code (at the latest main commit) onto the runner. \- **Auth Preparation:** Set up environment variables for auth. For PowerShell Graph SDK, we can simply ensure AZURE\_CLIENT\_ID, AZURE\_TENANT\_ID, AZURE\_CLIENT\_SECRET are in env and call Connect-MgGraph \-EnvironmentVariable[\[15\]](https://techcommunity.microsoft.com/blog/intunecustomersuccess/configuration-as-code-for-microsoft-intune/3701792#:~:text=,secret%20of%20the%20client%20app). For Python, we might export these to environment and use MSAL to get a token, or rely on IntuneCD’s built-in auth (which also can use env vars or an auth file). \- **Run Export Scripts:** Invoke each module. This could be done in a single PowerShell script that calls all sub-scripts sequentially, or as separate steps for each category. For example: \- \- name: Export Compliance Policies (PowerShell), run a pwsh script that calls our compliance export. \- \- name: Export Config Profiles (Python), run a python script. \- (The steps can use uses: azure/powershell@v1 action or simply the pwsh shell on a Windows runner.) \- We will install any required modules/tools in prior steps. E.g., Install-Module Microsoft.Graph.Intune or pip install intunecd. If using IntuneCD, one step is pip install IntuneCD then IntuneCD-startbackup command[\[18\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=IntuneCD,built), specifying output format and path. \- **Diff Step:** After exports, run the diff generator script (ensure both current and previous data are available – since the repo was checked out, we have the previous files; the export scripts likely overwrote or added new files in the working copy). \- **Commit Changes:** Use a GitHub Action to commit all changes. We’ll likely use the built-in github-token (which has write access to the repo) to commit. We’ll configure commit message to include the date and perhaps a summary (e.g., “Intune backup: week 2025-08-20”). We ensure to add and commit the new/changed files (git add . before commit). If required (for triggering external actions), we might push a tag or release; but primarily, committing to main branch is sufficient for backup. (In Aaron Parker’s example, they also tag each backup to create a release of documentation[\[19\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=For%20GitHub%2C%20I%E2%80%99ve%20created%20two,workflow%20performs%20the%20following%20steps)[\[20\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=Release%20Workflow) – we may not need that for our change log, but it’s an idea for marking points in time.) \- **Notifications (optional):** We could add a step to create an issue or send a Slack/Teams message if the diff has certain types of changes (for example, alert if a particularly sensitive policy changed). This is beyond the core requirement but an example of extension.

The workflow will be kept relatively simple and robust. If any step fails (e.g., Graph API call fails), the job fails – we’ll get notified via the Actions UI or configured integrations. We will also implement basic retry logic for Graph calls in the scripts to handle transient issues.

**6\. Grafana Integration:** The final piece is to make use of the JSON change log in Grafana (or similar monitoring tool). Our plan is to have Grafana periodically pull the latest changeLog.json from the repo (we can expose a read-only access token or use GitHub’s API to fetch the raw file). Grafana can then use a JSON data source or simple plugin to parse it. We will create a Grafana dashboard to visualize changes over time. For example: \- A table listing recent changes (with columns: date, object, change type, details). \- A graph counting how many changes per week, or a pie chart of added vs modified vs removed items. \- If desired, set up alerts in Grafana for certain conditions (e.g., “alert me if a Compliance Policy is removed” or if more than X changes happened outside business hours, etc.).

This step ensures that the information captured by the backup pipeline is readily accessible to the team. Rather than combing through git diffs, we have an easy visual way to review and audit changes. Grafana can also correlate this with other data (for instance, overlay Intune changes with incident timelines).

**7\. Testing and Rollout:** We will test the pipeline in a non-production Intune environment or using a test tenant (if available). The test will verify that: \- All intended components are exported correctly and files appear in the repo. \- The diff generation correctly identifies changes. We can simulate a change by altering a policy between runs and ensuring it shows up in the log. \- Permissions are sufficient (no Graph permission errors) and secrets are configured right. \- Performance: the whole job should ideally complete within a few minutes. (Intune might have dozens of objects; Graph calls are typically fast. If any category is very large, we might consider multi-threading or parallel jobs, but likely not needed.)

Once validated, we schedule the workflow against the production tenant (pointing the app registration to prod Intune). The first run will commit the entire baseline of configuration. We should review that commit carefully (and possibly tag it as baseline). Subsequent runs will then produce diffs relative to that baseline.

**8\. Documentation and Handoff:** We will document how the system works, how to run it on-demand, and how to onboard other tenants. Because we designed with environment variables, onboarding a new organization’s Intune is as simple as setting up an app registration for that tenant and configuring the secrets (or .env) accordingly, then running the workflow in that context. We’ll also include instructions for adding a new Intune component export module (for future Intune features): basically create a new script, drop it in the workflow, ensure it outputs to the repo.

Following this plan, we expect to have a functioning backup & monitoring system for Intune within a few development iterations. We will iterate as needed (for example, if we find that certain Intune objects aren’t covered by Graph v1.0, we might call beta endpoints or adjust the approach).

## Tradeoffs

* **GitHub vs GitLab (or Azure DevOps):** We chose GitHub because our organization already uses it for code and because **GitHub Actions** provides an easy way to schedule workflows and integrate with the repository. GitHub offers rich workflow support and free private repos[\[21\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=%2A%20GitHub%20,feature%20rich%20and%20well%20supported). However, some enterprises prefer GitLab or Azure DevOps for hosting code and pipelines. GitLab CI could achieve the same outcome – it has scheduling and a secure variables store. If using GitLab, we’d need to translate the workflow YAML and ensure runners have the necessary environment. One advantage of GitLab or Azure DevOps is tighter integration with Azure AD (Azure DevOps can use AAD for auth and maybe slightly easier secret management in some cases[\[22\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=feature%20rich%20and%20well%20supported%2C,feature%20rich%20and%20well%20supported)). In our case, using GitHub is suitable, but the design is **platform-agnostic**: all logic is in scripts that can be run in any CI system. Indeed, others have successfully implemented Intune backup on Azure DevOps as well[\[23\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=I%E2%80%99ll%20cover%20the%20setup%20of,hosting%20option%20for%20production%20environments). We also note that if company policy disallows storing this data on GitHub cloud, a self-hosted GitLab or Azure DevOps server could be used – tradeoff being more maintenance overhead for those platforms. We’ll proceed with GitHub but remain cognizant that switching to GitLab later is possible with minimal changes (as evidenced by community scripts adding GitLab support due to demand[\[24\]](https://andrewstaylor.com/2022/12/07/intune-backing-up-and-restoring-your-environment-new-and-improved/#:~:text=Update%20%E2%80%93%2002%2F08%2F2023)).

* **PowerShell vs Python for Scripting:** Our solution deliberately uses both, which might seem complex, but it plays to each language’s strengths. **PowerShell** is naturally suited for administrators familiar with Microsoft tools; it has a Microsoft Graph module that can directly call Intune APIs and output objects easily to JSON. Many Intune samples and earlier backup scripts are in PowerShell (e.g., the IntuneBackup module[\[4\]](https://www.thelazyadministrator.com/2019/11/26/backup-and-restore-your-intune-configuration-using-powershell/#:~:text=I%20found%20this%20fantastic%20PowerShell,compare%20different%20Intune%20backup%20sets) and various Graph call examples), so reusing or adapting those is faster. On the other hand, **Python** offers powerful JSON handling, cross-platform ease (especially on Linux runners), and libraries like IntuneCD which already implement backup logic in a robust way[\[5\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=The%20IntuneBackupAndRestore%20PowerShell%20module%20has,single%20tenant%20or%20across%20tenants). Python’s Microsoft Graph SDK (or MSAL) can be used for Graph calls as well. Using Python might reduce complexity for diff generation and allow leveraging existing open-source projects. The trade-off is that mixing languages requires both environments to be set up in the CI, and developers maintaining this need familiarity with both. We mitigate this by clear module boundaries – e.g., a team PowerShell expert can maintain the PS scripts while a Python expert handles the diff tool, without their work overlapping. We also considered doing everything in one language: doing all exports in PowerShell is possible but parsing JSON and doing complex diff might be harder in PS; doing everything in Python is possible (IntuneCD shows it) but some Intune quirks (like converting PowerShell scripts to base64 and back) might be easier with PowerShell libraries[\[25\]](https://rozemuller.com/manage-intune-scripts-with-github-actions/#:~:text=Base64%20encoding). By using both, we’re opting for **stability and productivity** over uniformity. Should maintenance become an issue, we could refactor to one language later. The modular approach means even if one module is PowerShell today, we could rewrite it in Python tomorrow (or vice versa) without affecting others, as long as it produces the same output.

* **JSON vs YAML for Config Format:** We plan to use JSON because it’s the native format of Graph API and easily consumable by our diff tool and Grafana. YAML is human-friendlier for reading, and IntuneCD can output YAML[\[26\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=the%20%60IntuneCD,from%20the%20exported%20configuration%20files). But since we are focusing on automation and JSON diff, JSON is more straightforward (and eliminates format quirks or comments that YAML could introduce). JSON also avoids any ambiguity in how data types are represented. The change log itself will definitely be JSON (Grafana can parse JSON readily). So we trade a bit of human readability for standardization and machine processing. (We can always convert JSON to a markdown or PDF report for human consumption later, similar to what IntuneCD’s documentation generation does, but that’s a bonus feature outside scope.)

* **Weekly Schedule vs Real-time Trigger:** We chose a weekly cron job as per requirements – meaning changes will be picked up at most within a week. The tradeoff is if someone makes a change and wants it tracked immediately, they either wait or manually trigger the workflow. An alternative could be to run daily or even attempt to trigger on changes. However, Intune doesn’t have webhooks for config changes, and too frequent runs might be overkill and increase noise (most teams don’t change Intune daily). Weekly is a good balance to catch changes in a reasonable time frame with minimal overhead. It also aligns with typical change management cycles (weekly review). If needed, we can adjust the schedule easily or allow manual runs for exceptional cases. The cron approach is simple and reliable.

In summary, our tradeoff decisions favor a solution that is **practical, maintainable, and aligns with team skills**. We acknowledge that using GitHub and a mix of PowerShell/Python is not the only way – it’s just the way that best fits our current environment and can be implemented quickly with low risk. We remain open to evolving these choices if circumstances change (for example, if our company moves to GitLab, or if Microsoft releases a new official tool/SDK that renders one approach more appealing).

## Service Dependencies

Our system depends on several services and components, each of which is critical to the overall functionality. Below we outline these dependencies and the impact if they are unavailable or slow:

* **Microsoft Graph API (Intune Service):** This is the primary cloud API we call to read Intune configurations. **Impact if unavailable:** The backup run will fail to fetch data. If Graph is temporarily down or returns errors, our workflow may fail that week (and we’d catch up on next run). We will implement retries for transient failures, but a prolonged Graph outage means no backup – which is acceptable in the short term since the last known good state is still in Git. (Intune’s portal itself would be down too in that scenario.) We might add logic to notify if Graph API calls consistently fail.

* **Azure AD (Authentication):** The app registration and OAuth flow depend on Azure AD functioning to issue tokens. **Impact if unavailable:** If Azure AD is down, our scripts can’t authenticate to Graph, and thus backup fails. This is rare, but again the system would simply try next time. We will ensure the app’s secret is valid and rotated as needed to avoid auth failures due to expired credentials.

* **GitHub Actions Service:** The cloud CI runners and workflow execution depend on GitHub’s infrastructure. **Impact if unavailable:** If GitHub Actions is experiencing an outage or if our organization’s Actions usage is hitting limits, the scheduled job might not run at the expected time. A delay in a weekly backup is not catastrophic; the workflow would run once service is restored (or we can manually run it). If an outage caused a run to be skipped entirely, we have a gap of one week – not ideal but recoverable. GitHub provides status notifications we can monitor. As a mitigation, we could set up a secondary method (like an Azure Automation runbook) as a fail-safe, but that adds complexity. Given weekly frequency, we accept this dependency.

* **Git Repository (GitHub hosting):** The repository is where data is stored long-term. **Impact if unavailable/sluggish:** If GitHub itself is down at commit time, the workflow might fail when pushing changes. We could potentially lose a backup iteration (though the data was fetched, it wouldn’t be saved to repo). If GitHub is slow, the commit step might timeout. We can retry or push later. The repository must also have sufficient storage (but text JSON files even for large Intune environments are likely only a few MB at most, which is fine). We rely on Git for versioning; any corruption there would be serious but is very unlikely on a managed service like GitHub.

* **Grafana (Monitoring system):** Grafana is downstream – the backup can function without Grafana, but our visibility would be reduced. **Impact if unavailable:** If Grafana is down, it doesn’t stop backups, but no one will see the nice dashboards. If Grafana or its data source fails to fetch the JSON, we might miss alerts. To mitigate, we might add an alternate notification (like email diff report). Grafana performance is not critical for the pipeline, but important for end-user consumption.

* **Intune/CDK Tools (PowerShell/Python modules):** Our process depends on certain libraries or modules (like the Microsoft Graph PowerShell SDK, IntuneCD Python package, etc.). **Impact if unavailable:** If these packages were yanked or updated in a breaking way, our scripts could fail. We pin versions where possible (for example, using a specific IntuneCD version known to work). If an update to Graph API changes some JSON fields, our diff logic might misbehave until updated. We treat this as maintenance overhead – the pipeline will alert us by failing or producing unusual diffs if something changes in the data format.

* **Network/Connectivity:** The runner executing the job needs network access to Graph and to GitHub. **Impact if restricted:** If we ever run this on a self-hosted runner behind a firewall, we must allow egress to Graph API endpoints and to GitHub. Lack of connectivity would prevent operation. On GitHub-hosted runners, Microsoft manages this (they have internet access by default).

In summary, the most critical dependencies are the **Microsoft Graph API** and **GitHub platform**. A failure in either around the scheduled time could cause a missed backup. We accept that risk given the non-real-time nature of backups, but will build in monitoring so we know if a scheduled run failed. Since this system is read-only and for internal use, the impact of a single failure is low (we don’t anticipate needing to recover Intune config on an hourly basis). Over a longer term, repeated failures would be noticed and addressed (e.g., if Graph changes require script updates). Each dependency will be documented so operations teams know where to check (Graph API status, GitHub status) if there’s an issue with the backups.

## Metrics

We will track several metrics to evaluate the success and health of the Intune backup system:

* **Backup Job Success Rate:** The percentage of scheduled backup runs that complete successfully. We expect \~100% success over time. If the success rate dips (due to errors in the workflow, auth failures, etc.), that’s a trigger to investigate. This metric can be obtained from GitHub Actions (e.g., number of failed runs in past quarter).

* **Backup Duration:** How long each backup job takes to run. We will monitor the job logs to establish a baseline (say it takes 2 minutes on average). Significant increases in duration might indicate more Intune objects (growth of config) or a hang in one of the export scripts. We aim to keep the duration under \~10 minutes for maintainability.

* **Coverage of Intune Objects:** We can define the number of Intune object categories backed up vs. total available. For example, if Intune has 10 categories of settings and we back up 9, we have 90% coverage. Our goal is 100% coverage of all supported Intune config types. As new policy types are introduced by Microsoft, we measure whether we’ve added them. This is a qualitative metric but ensures our backup doesn’t miss anything important.

* **Number of Changes Detected Per Interval:** From the JSON change logs, we can derive how many changes (added/removed/modified) occur in each week’s run. This metric is useful for the team’s awareness: e.g., an average of 5 changes per week. A spike to 50 changes in a week might indicate either a major revision (planned) or something problematic (someone bulk-modified policies unexpectedly). Grafana can plot this over time easily (count of array items in change log).

* **Time to Identify Critical Change:** This is more of an operational metric – if a breaking change was made in Intune, how quickly can we find it via the system. Since the backup is weekly, worst-case is under 7 days. If we incorporate alerts for certain changes, we could measure the time from change commit to alert. Our design could allow near-immediate identification if we trigger a run manually when needed.

* **Data Consistency Metric:** We might periodically validate that an export and immediate re-export produce no differences. This sanity check ensures our diff logic isn’t flagging false changes. Essentially, if no actual change was made in Intune between runs, the “modified” count in change log should be zero. If not, something’s off (maybe non-deterministic ordering in JSON). We will aim for a metric of “false positive diffs \= 0”.

* **Resource Usage Metrics:** Though minor, we might keep an eye on how much repository storage is used or how large the JSON files get over time. This is to ensure the repo remains manageable. If the JSON logs grow without bound, we might decide to purge or archive older ones after X time. This metric could be size of Intune/ folder in Git or count of files.

* **Security Metrics:** For instance, ensure that all commits are signed (if we require that) and the secrets have not been accessed outside of runs. We could log or count access to the secrets (GitHub doesn’t provide direct metrics, but we know only Actions should access them). Another indirect metric: ensure the Graph app is not used beyond this process (monitoring its sign-in logs).

We will surface key metrics on a Grafana dashboard or at least review them in team meetings. Particularly, the **change count** and **successful run** metrics will be highlighted. Over the first few months, we expect to see a steady cadence of changes which helps establish configuration baseline volatility. If metrics show anomalies (e.g., backup job failing repeatedly or huge change bursts), that prompts action (fix scripts or check if someone did bulk changes intentionally).

## Security Considerations

Security is paramount since we are dealing with sensitive configuration data and privileged access to our Intune tenant. Here we address security aspects:

* **Data Sensitivity and Repository Access:** Intune configuration can reveal a lot about our security posture – e.g., compliance rules, password requirements, which apps are allowed, etc. In the wrong hands, this information could be used to plan attacks. Therefore, the Git repository containing the backups **must be private and tightly controlled**[\[12\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=It%E2%80%99s%20vitally%20important%20that%20the,how%20you%20secure%20your%20devices). Only authorized team members (e.g., Intune admins or engineers maintaining this system) should have read access. We will enforce branch protections and perhaps require approval for changes to the backup process itself (though the config data will just be auto-committed by the bot account). We might also use Git encryptions or at least monitor access logs to this repo. In Parker’s implementation, he explicitly notes the repo should be private due to the sensitivity[\[12\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=It%E2%80%99s%20vitally%20important%20that%20the,how%20you%20secure%20your%20devices) – we will do the same and treat the backup files as **confidential internal data**.

* **Credential Security:** The Azure AD app’s client secret is a highly sensitive piece, as it grants read access to Intune via Graph. This secret will be stored in GitHub Actions secrets, which are encrypted at rest and only exposed to the workflow at runtime. We will ensure not to print the secret in logs (using GitHub’s masking which is automatic for secrets). The secret will also be periodically rotated (for instance, if it’s valid for 1 or 2 years, we set reminders to update it before expiration). Additionally, in the Graph permissions, we chose app-only **read** permissions. The app **cannot make changes** in Intune (no write permissions). This principle of least privilege means even if the secret were somehow leaked, the impact is limited to data exposure, not altering configurations. We’ll document the exact permissions granted (read all device management configs, read RBAC, read devices maybe if needed for assignments, etc.). If more sensitivity is needed, we could also consider using a certificate credential instead of a client secret, to avoid stored secrets – but that adds complexity in GitHub Actions (we’d need to import the cert and key securely).

* **Graph API Scope and Constraints:** One security consideration is that Graph API might include certain secrets in config output. We have to be careful about **what we export**. For example, Intune config might include:

* Wi-Fi profiles with pre-shared keys,

* VPN profiles with shared secrets,

* Client app config with credentials,

* Certificates (public and maybe private if using PFX? though Intune likely doesn’t export private keys).

We need to ensure we do not inadvertently store any **clear-text secret** in the repo. Ideally, Graph API does not return secrets or returns placeholders (for instance, some APIs return “***\******\*” for secret fields). We will verify: e.g., for Wi-Fi profile, does Graph give the actual Wi-Fi password? If yes, we should consider masking or excluding that field in the JSON. Another approach: we could hash or redact known sensitive fields in our export scripts. It’s a balance – including them might help in full restoration, but it significantly raises the sensitivity of the backup (and those secrets could rotate anyway making backup less useful). We will likely** exclude extremely sensitive secrets\*\* from the backup (or store them in a separate secure vault if needed). Our primary focus is on policy settings, not credentials.

Also, the JSON change logs we produce will be reviewed to ensure we don’t log any sensitive value. The diff should be at a high level (e.g., “WiFi password changed” rather than revealing the old and new passwords – if we can even detect that, which we might not if it’s hidden).

* **GitHub Actions Security:** We will run the workflow on GitHub-hosted runners to avoid maintenance, but we must consider that these runners are ephemeral and managed by GitHub. The secrets are injected into them and erased after use. We trust GitHub’s security here. If using a self-hosted runner, we’d ensure it’s a secure environment (patched OS, limited network access, etc.). All dependencies installed in the runner come from official sources (PowerShell Gallery, PyPI). We will pin versions to avoid pulling a compromised update. There is a small risk in depending on an open-source tool (IntuneCD) – if it’s compromised on PyPI, that’s a supply chain risk. To mitigate, we can vendor a specific version or at least verify its integrity (perhaps by checking hash or using GitHub’s Dependabot alerts for any known vulnerabilities in the packages).

* **Logging and Audit:** We will keep logs of each backup run (GitHub Actions logs). These logs might contain some output from Graph calls. We’ll scrub or avoid logging sensitive data in those. But we will log enough to audit that the process ran properly. Additionally, Azure AD logs will show that our app registration is being used to pull data. We could have Security Operations monitor that service principal’s usage to detect any anomalies (e.g., if it were used outside of the scheduled time, that could indicate a credential leak).

* **Grafana Access:** The change log will be surfaced in Grafana for convenience. We must ensure the Grafana dashboard that displays this data is only accessible to appropriate personnel (e.g., internal IT staff). If Grafana is part of our secure network, we’ll integrate it with SSO. Essentially, treat the change log data with similar sensitivity – it might not have raw secrets, but it clearly enumerates our internal policies. We wouldn’t want that public.

* **Potential for Abuse:** Since this is a one-way backup, the risk of the system itself making unwanted changes is low (we intentionally do not include any Graph write operations). The main risk is exposure. However, one subtle risk: if an attacker gained access to the GitHub repo, they could see all configs and also possibly commit a fake change log or manipulate it. While that wouldn’t directly change Intune, it could mislead our team. To mitigate, we restrict repo access and could even enforce commit signing. We might use a specific machine user or bot account for the commits with a GPG key, and require signed commits (as Parker did in his example[\[27\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=commits%20%2A%20%60GPGKEY%60%20,unlocking%20the%20GPG%20signing%20key)). This ensures the integrity of the repo – we know changes came from our workflow, not an outsider.

In conclusion, our approach is to **minimize privileges and secure data at rest and in transit**. The repo is private, the credentials are limited and stored securely, and the output is scrubbed of any unnecessary secrets. We will regularly review the security posture: e.g., review who has access to the repo, rotate the app secret, and update permissions if we realize we granted more than needed. We’ll also follow Microsoft’s best practices for Graph API automation (like using certs or managed identities if we ever move to Azure-hosted solutions). By containing everything within known boundaries, we aim to make the security risk of this project low, while greatly enhancing our visibility into Intune changes.

## Cloud Questions

We address some common cloud-related concerns for this solution in a Q\&A format:

**Q1: Does this solution rely on any external SaaS or cloud services, and are they approved for use?**  
**A1:** Yes. It relies on **GitHub (SaaS)** for both source control and CI runner, and on **Microsoft Azure/Microsoft Graph** (which Intune is a part of) for data access. GitHub is an external cloud service – we will use it in accordance with company policy (e.g., using enterprise GitHub if available, and ensuring the repo is private)[\[12\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=It%E2%80%99s%20vitally%20important%20that%20the,how%20you%20secure%20your%20devices). Intune itself is already a cloud service in use. We are not introducing a new cloud product beyond what’s already in use (GitHub is likely already used for code; if not, we’d go through a security review for it). If company policy required, we could alternatively use an internal Git service or Azure DevOps (which is also cloud but considered more aligned with Azure). We will ensure the **data stays in a private repository** and doesn’t go to any public cloud storage or forums. All cloud usage is intentional and approved for this project’s needs.

**Q2: Where is the data stored and what about data residency/compliance?**  
**A2:** The Intune data is exported and stored in GitHub’s servers (which may be in the US or other regions depending on our GitHub enterprise settings). This means a copy of our device management configurations will reside outside of Microsoft’s cloud (Azure) and into GitHub’s cloud. If data residency is a concern, we might need to configure GitHub to use certain regions or consider self-hosting the git repository. However, Intune config data doesn’t typically include personal data (see Privacy section) but is still sensitive corporate data. We will verify with compliance if storing this on GitHub is acceptable. Generally, config metadata is not regulated data like PII or financial info, so residency requirements may be less strict. We will document the data content and get approval that storing it on GitHub is okay. Our alternative plan, if not, would be to use an Azure DevOps repo which keeps data in Azure (or even an on-prem GitLab). But that adds complexity, so we prefer GitHub if allowed.

**Q3: How will access to the cloud resources be governed?**  
**A3:** Access to the GitHub repo will be managed via GitHub’s access controls (only our team and perhaps specific service accounts have access). We’ll tie it into SSO if possible for user access. The Azure app registration’s credentials are only in the GitHub Action, not shared interactively. No human will directly log in with that app – it’s purely for the automation. In Azure AD, we can apply Conditional Access policies if needed (e.g., allow the app to sign in only from GitHub Action IP ranges – though that might be complex). We’ll audit the app’s usage logs periodically. As for Grafana, if it’s also cloud (could be self-hosted or a cloud service), we’ll ensure any integration (like pulling from GitHub API) uses a read-only token and principle of least privilege.

**Q4: What if we switch cloud providers or need to migrate away from GitHub?**  
**A4:** The design is not locked into GitHub specifically. If we needed to migrate to **GitLab or Azure DevOps** pipelines due to a company decision, we can do so with minimal changes (mostly rewriting the pipeline syntax and storing secrets in the new pipeline’s secret store). Our code modules (PowerShell/Python) remain reusable. The repository content itself can be migrated by pushing it to a new git remote. The JSON logs and config histories are portable. So, while we use GitHub Actions now for convenience, we have an exit strategy if needed – basically the scripts can run in any environment that supports PowerShell/Python and Git.

**Q5: Does this project incur any cloud costs?**  
**A5:** Using GitHub Actions within the included minutes of our plan is essentially no additional cost (or a negligible cost if we exceed free minutes). Each run is a few minutes of a runner – well within free tier for weekly usage. GitHub private repos have no cost for our enterprise account (assuming we have that). Grafana could be self-hosted or part of an existing license. Azure AD app registrations are free; Graph API calls are free up to very high volumes. So, the cost impact is minimal. We will monitor if API call volume becomes high (but Intune tenants with thousands of objects would still be fine).

**Q6: Is any data sent to third-party services outside our control (besides GitHub)?**  
**A6:** Not really. The data flows from Microsoft Intune (Microsoft’s cloud) to GitHub (our cloud repo). Grafana will fetch data from GitHub. We aren’t sending data to any unknown third parties. All services involved (Microsoft, GitHub, Grafana if cloud) are ones we have relationships with and have likely approved in our vendor management. If Grafana is self-hosted, then it’s internal anyway. We have to be mindful that by storing on GitHub, we are effectively entrusting our data to that third-party – hence all the precautions about it being private and secure.

By addressing these cloud questions, we ensure stakeholders (especially security and compliance teams) are comfortable with the use of cloud in this project. We confirm that we’re leveraging cloud services in a responsible, compliant manner and have contingency plans if needed.

## Privacy Considerations

From a privacy standpoint, we need to analyze what data is being handled and whether it includes any personal or user-specific information:

* **Nature of Data Collected:** The system is exporting **configuration data** from Intune – things like policy settings, profile names, and assignment group IDs. Generally, this is not personal data about employees or customers; it’s IT policy data. For example, a compliance policy might say “require password of 6 characters” – no personal info there. However, there are a few aspects to watch:

* **Policy names or descriptions** might sometimes include a person’s name or location (if an admin named something like “John’s iPhone Policy” – but that’s rare and not best practice). We will scan our Intune for any policy names that include personal identifiers. If they do, those would end up in the backup. That is still relatively low sensitivity (a first name in a policy name), but worth noting.

* **Group Names and IDs:** Assignments are often to Azure AD groups. Group names could be things like “All Marketing Users” or “Devices in Toronto”. Those aren’t personal, but what if there’s a group named after a person (e.g., a dynamic group for a single exec)? Unlikely, but if so, that person’s name would appear. Even group IDs (GUIDs) themselves are not personal data.

* **Intune roles and admins:** Backing up RBAC roles might include the mapping of which user identities are in a role (if we choose to export assignments of roles). For instance, if John Doe is an Intune Admin and we export that “Intune Admin role has member JohnDoe@company.com”, that is personal data (an identifier of an employee). Do we need to export the membership of roles? It could be useful, but it does cross into listing staff names. We have a choice: we might exclude actual user assignments from the backup to avoid that. Or include it for completeness but then treat the backup as containing some personal data. If included, that data is still within a private repo accessible only to IT, so privacy impact is minimal (it’s basically an internal list of admins, which we already have elsewhere). We will document this and possibly get approval that including admin names is acceptable. Alternatively, we could export role definitions (permissions) but not who is assigned. That would avoid storing personal info. Since the focus is on configurations, we can likely skip user-specific data.

* **Audit logs (who made change):** The Reddit post hinted IntuneCD could capture “who made the change”[\[28\]](https://www.reddit.com/r/Intune/comments/1czjd7y/intune_configuration_profiles_backup_in_json/#:~:text=IntuneCD%20%2B%20azure%20pipeline%20https%3A%2F%2Fdoitpshway.com%2Fhow,pipeline). If we attempted to include that (by querying Intune’s audit logs for each change), we would definitely be recording personal data (the admin’s identity) in the change log. The requirement didn’t explicitly ask for that, and it complicates things. For privacy and simplicity, we are **not** including user names of who did what in the JSON change log. We only capture what changed, not by whom. If needed, that info can be obtained from Intune audit logs separately with proper authorization. This keeps our change log free of personal identifiers, focusing purely on config differences.

* **Data Minimization:** We will only back up data necessary for the purposes of configuration restore or analysis. We won’t, for example, query device records or user inventories – that would be out of scope and could include personal/device-specific data. We strictly limit to configuration settings. This aligns with privacy best practices by minimizing data collection.

* **Storage and Retention:** The backups will reside in Git indefinitely unless cleaned. Does this pose any privacy issue? If a policy name had a person’s name and that person leaves, that reference stays in git history. Under regulations like GDPR, an individual could request their data be erased. However, configuration data references to a first name might not qualify as personal data in use (especially if it’s not identifying a person’s data but just a label). We should still consider if we need a retention policy for backups. Perhaps we decide to keep all history as it’s valuable for config audit (and likely harmless). If needed, we could purge or anonymize entries if any personal data is found. Realistically, the chance of storing meaningful personal data is low.

* **Consent and User Expectation:** Employees expect that IT is managing their devices and configurations. Our system doesn’t increase monitoring of individuals; it’s monitoring IT changes. So it doesn’t impact employee privacy directly. We are not collecting any data from user devices or about user behavior – just IT-set rules.

* **Sensitive Info:** As discussed in security, one area to watch is if any Intune config contains something like a personal identifier. For example, a Win32 app configuration might include a path with a username? Unlikely, but we’ll double-check that nothing like device names (which might contain usernames) are being exported. Intune device objects (with device name like “JohnDoe-Laptop”) are not in scope to export – we focus on policies. So we avoid exporting lists of devices or users targeted by name.

* **Third-Party Exposure:** The data will be in GitHub’s cloud (private). GitHub, as a processor of our data, will have its own privacy and security measures. We should ensure this aligns with our internal privacy policies (e.g., not putting employee personal data on external services without consent). Since we have minimized personal data, this should be fine. If we had significant personal data, we’d need to perhaps have a Data Processing Agreement with GitHub, etc. Not needed at our scale of data.

In conclusion, the privacy impact of this project is low. We mostly deal with configuration settings, not personal information. To be safe, we will: \- Avoid including any user-specific details in the backup if not needed. \- Keep the repository access limited to those with a need to know (which also protects any minor personal references that might appear). \- Be transparent internally about what we’re storing (for instance, if someone asks, we can show that we’re not storing employees’ data, just IT configs).

We will document that no customer data is involved, and employee data involvement is minimal (possibly admin names if at all). This should satisfy privacy officers that this project doesn’t introduce new privacy risks.

## Impact of Migration

This section discusses how adopting this new backup-as-code system will impact our current processes and any migration considerations from existing solutions:

* **Current State vs New State:** Currently, any backup of Intune (if done at all) might be manual or using scripts run occasionally. There is no consistent version control. By migrating to the new system, we establish an authoritative repository for Intune configuration. Teams that used to rely on manually checking Intune for settings or maintaining wiki documents will now refer to the Git repo or Grafana for historical configs. This is a positive change, but requires a mindset shift: we should train our IT support and engineers to consult “the code” for Intune settings (especially if diagnosing when a setting changed).

* **No Disruption to Intune Service:** Importantly, this system is **read-only** with respect to Intune. It does not deploy any change to endpoints or Intune itself. So it will not impact end users or devices. The Intune service will continue to operate as normal. The only interaction is API reads, which are low impact. Microsoft’s Intune Graph can handle frequent reads easily, and our usage is moderate (weekly). There’s no risk of throttling at our frequency – and even if, Graph would return rate-limit errors which we can handle by slowing queries. So device management and end-user experience remains unchanged.

* **Integration with Change Management:** If the organization has a formal change management process for Intune (e.g., CAB approval for policy changes), this system becomes a complementary tool. After migration, for each approved change, one can verify in the next backup commit that the change is present and correct. It provides accountability. Over time, we might even integrate – e.g., include change ticket IDs in commit messages, or use the diff log to automatically populate change records. Initially, it’s separate, but the team will likely appreciate having a clear record. The impact is mainly cultural: embracing an “infrastructure as code” approach.

* **Replacement of Existing Backup Solutions:** Some teams or individuals might have their own scripts (like maybe someone runs Andrew’s intune-backup script periodically). Moving to this unified solution means those should be retired or at least not considered the source of truth anymore. We will communicate to any stakeholders currently doing Intune exports that this new repository will be the official source moving forward. If we have any data from previous backups, we might import it or archive it. For instance, if we have JSON from last month by some other method, we could commit that as the initial baseline to preserve history. But since our initial run will capture everything, that might suffice.

* **Rolling Out to Multiple Tenants:** If our company has multiple Intune tenants (perhaps a dev/test tenant and a prod tenant, or separate geographic tenants), using this tool across them will require some coordination. The design supports reuse – we’d just use different credentials and possibly a different repo or different branches/folders per tenant. The migration plan for those is similar: do an initial baseline export for each, review it, then schedule continuous backups. If using one repo for multiple tenants, we’d segregate by directory or branch.

* **Training and Documentation:** We will need to inform the IT admins and maybe Helpdesk about the new system. It might slightly impact how they retrieve information. For example, Tier 2 support could use Grafana to see if a policy changed recently when investigating an incident (“Oh, encryption policy changed last week, maybe that’s why…”). We will provide documentation on how to use the Grafana dashboard and how the data is structured. This is a positive impact – giving more insight – but requires a bit of enablement.

* **Ongoing Maintenance:** Adopting this system means we have an ongoing responsibility to maintain it. If Intune releases new features or deprecates APIs, we’ll need to update our export modules. That’s an impact in terms of workload: someone (or a small group) should be the owner of this system. We’ll outline an “ownership” in our team so that it doesn’t fall through the cracks. This is no different than any internal tool – just to note that Intune updates might necessitate script updates (for instance, if Microsoft Graph API versions change, etc.). We have mitigated this by using stable Graph calls and modular design.

* **Disaster Recovery and Migration:** In the unlikely scenario that we needed to restore Intune from scratch (e.g., tenant got wiped or we want to clone settings to a new tenant), our backup gives us a head start. The impact of having this in place is that we are much better prepared for a migration. We could write complementary import scripts (the inverse of our export) to push configs to Intune Graph. That could drastically reduce downtime if a migration or rebuild is needed. Essentially, we gain a form of **insurance**. While we’re not explicitly doing a migration now, the design addresses how one would be done (treat the JSON as source and apply to target tenant, possibly using IntuneCD’s import capabilities[\[29\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=,format%20from%20the%20exported%20configurations)). So future migrations or acquisitions where we need to replicate policies become easier – that’s a beneficial impact to note.

* **Impact on Git Workflow:** The repository will be mostly updated by the automation. This means humans typically shouldn’t be editing the config files in this repo by hand (at least not without coordination). We should clarify that process: perhaps mark the repo as one where direct commits to certain folders are discouraged because they’ll be overwritten by the next run. Or if someone wants to propose a config change via Git (for GitOps), that’s a future enhancement but not in initial scope. So short-term, no one manually changes this repo; it’s append-only via automation. That’s fine and doesn’t conflict with other workflows. It just means the repo will have frequent bot commits. We might want to use a dedicated GitHub identity (e.g., “intune-backup-bot”) for the commits to clearly distinguish them. Minor detail, but helps with clarity.

In summary, the migration to this new system is low-risk and high-reward. It doesn’t disrupt production or require any downtime. The main impacts are positive: improved visibility, better change tracking, and readiness for any restore/migrate needs. Internally, teams will gradually adjust to using the new tools (repo, JSON logs) instead of older manual methods. We will monitor the adoption – e.g., ensure people find the Grafana dashboard useful – and gather feedback. If any issues arise (like confusion over data or minor false diffs), we will address them in the early phases. Overall, this project will bolster our configuration management practices with minimal negative impact on current operations.

By implementing it carefully and educating the relevant teams, we expect the transition to be smooth and to quickly become an indispensable part of our endpoint management strategy. The end state is that Intune config management is no longer a black box, but a well-audited, versioned system – aligning with the company’s broader DevOps and compliance objectives.

---

[\[1\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=If%20there%E2%80%99s%20anything%20that%E2%80%99s%20certain,receives%20updates%20almost%20every%20week) [\[3\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=What%20is%20more%20valuable%20to,blame%20game%20is%20not%20healthy) [\[5\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=The%20IntuneBackupAndRestore%20PowerShell%20module%20has,single%20tenant%20or%20across%20tenants) [\[6\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=Hosting%20the%20exported%20configurations%20in,Git%20version%20history%20is%20easy) [\[8\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=Create%20the%20following%20secrets%20on,the%20repository) [\[9\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=This%20workflow%20performs%20the%20following,tasks) [\[10\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=,built%20in%20markdown%20format) [\[11\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=%2A%20%60CLIENT_SECRET%60%20,the%20user%20for%20Git%20commits) [\[12\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=It%E2%80%99s%20vitally%20important%20that%20the,how%20you%20secure%20your%20devices) [\[18\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=IntuneCD,built) [\[19\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=For%20GitHub%2C%20I%E2%80%99ve%20created%20two,workflow%20performs%20the%20following%20steps) [\[20\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=Release%20Workflow) [\[21\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=%2A%20GitHub%20,feature%20rich%20and%20well%20supported) [\[22\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=feature%20rich%20and%20well%20supported%2C,feature%20rich%20and%20well%20supported) [\[23\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=I%E2%80%99ll%20cover%20the%20setup%20of,hosting%20option%20for%20production%20environments) [\[26\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=the%20%60IntuneCD,from%20the%20exported%20configuration%20files) [\[27\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=commits%20%2A%20%60GPGKEY%60%20,unlocking%20the%20GPG%20signing%20key) [\[29\]](https://stealthpuppy.com/automate-intune-documentation-github/#:~:text=,format%20from%20the%20exported%20configurations) Automate Microsoft Intune As-Built Documentation on GitHub | Aaron Parker

[https://stealthpuppy.com/automate-intune-documentation-github/](https://stealthpuppy.com/automate-intune-documentation-github/)

[\[2\]](https://rozemuller.com/manage-intune-scripts-with-github-actions/#:~:text=Currently%2C%20Intune%20does%20not%20provide,committed%20to%20a%20GitHub%20repository) [\[25\]](https://rozemuller.com/manage-intune-scripts-with-github-actions/#:~:text=Base64%20encoding) Manage Intune Scripts With GitHub Actions

[https://rozemuller.com/manage-intune-scripts-with-github-actions/](https://rozemuller.com/manage-intune-scripts-with-github-actions/)

[\[4\]](https://www.thelazyadministrator.com/2019/11/26/backup-and-restore-your-intune-configuration-using-powershell/#:~:text=I%20found%20this%20fantastic%20PowerShell,compare%20different%20Intune%20backup%20sets) [\[16\]](https://www.thelazyadministrator.com/2019/11/26/backup-and-restore-your-intune-configuration-using-powershell/#:~:text=If%20I%20navigate%20to%20that,will%20be%20PS1%20source%20files) [\[17\]](https://www.thelazyadministrator.com/2019/11/26/backup-and-restore-your-intune-configuration-using-powershell/#:~:text=To%20now%20compare%20both%20configuration,My%20full%20scriptblock%20would%20be) Backup and Restore your Intune Configuration using PowerShell \- The Lazy Administrator

[https://www.thelazyadministrator.com/2019/11/26/backup-and-restore-your-intune-configuration-using-powershell/](https://www.thelazyadministrator.com/2019/11/26/backup-and-restore-your-intune-configuration-using-powershell/)

[\[7\]](https://andrewstaylor.com/2022/12/07/intune-backing-up-and-restoring-your-environment-new-and-improved/#:~:text=,new%20Graph%20SDK) [\[24\]](https://andrewstaylor.com/2022/12/07/intune-backing-up-and-restoring-your-environment-new-and-improved/#:~:text=Update%20%E2%80%93%2002%2F08%2F2023) Intune – Backup and Restore your environment – Andrew Taylor

[https://andrewstaylor.com/2022/12/07/intune-backing-up-and-restoring-your-environment-new-and-improved/](https://andrewstaylor.com/2022/12/07/intune-backing-up-and-restoring-your-environment-new-and-improved/)

[\[13\]](https://github.com/almenscorner/IntuneCD/discussions/153#:~:text=It%20should%20be%20enough%20with,All) [\[14\]](https://github.com/almenscorner/IntuneCD/discussions/153#:~:text=To%20export%20the%20roles%20the,All%20correct) Feature Request \- Backup of Intune Roles and Scope Tags · almenscorner IntuneCD · Discussion \#153 · GitHub

[https://github.com/almenscorner/IntuneCD/discussions/153](https://github.com/almenscorner/IntuneCD/discussions/153)

[\[15\]](https://techcommunity.microsoft.com/blog/intunecustomersuccess/configuration-as-code-for-microsoft-intune/3701792#:~:text=,secret%20of%20the%20client%20app) Configuration as Code for Microsoft Intune | Microsoft Community Hub

[https://techcommunity.microsoft.com/blog/intunecustomersuccess/configuration-as-code-for-microsoft-intune/3701792](https://techcommunity.microsoft.com/blog/intunecustomersuccess/configuration-as-code-for-microsoft-intune/3701792)

[\[28\]](https://www.reddit.com/r/Intune/comments/1czjd7y/intune_configuration_profiles_backup_in_json/#:~:text=IntuneCD%20%2B%20azure%20pipeline%20https%3A%2F%2Fdoitpshway.com%2Fhow,pipeline) Intune Configuration Profiles \- Backup in Json : r/Intune

[https://www.reddit.com/r/Intune/comments/1czjd7y/intune\_configuration\_profiles\_backup\_in\_json/](https://www.reddit.com/r/Intune/comments/1czjd7y/intune_configuration_profiles_backup_in_json/)
